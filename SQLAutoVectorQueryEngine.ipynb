{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-QrAYiSbnrc"
      },
      "source": [
        "# Combining Structured and UnStructured data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "7EbOfXq9bnrd"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv(\".env\", override=True)\n",
        "openai.api_key = os.environ[\"OPENAI_API_KEY\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ZT6w2Jj9bnrf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting llama-index==0.9.31\n",
            "  Using cached llama_index-0.9.31-py3-none-any.whl (15.8 MB)\n",
            "Requirement already satisfied: wikipedia in .\\llamaindex\\lib\\site-packages (1.4.0)\n",
            "Requirement already satisfied: openai>=1.1.0 in .\\llamaindex\\lib\\site-packages (from llama-index==0.9.31) (1.14.1)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in .\\llamaindex\\lib\\site-packages (from llama-index==0.9.31) (3.8.1)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.2 in .\\llamaindex\\lib\\site-packages (from llama-index==0.9.31) (4.12.2)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in .\\llamaindex\\lib\\site-packages (from llama-index==0.9.31) (8.2.3)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in .\\llamaindex\\lib\\site-packages (from llama-index==0.9.31) (1.5.9)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in .\\llamaindex\\lib\\site-packages (from llama-index==0.9.31) (0.9.0)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in .\\llamaindex\\lib\\site-packages (from llama-index==0.9.31) (4.9.0)\n",
            "Requirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in .\\llamaindex\\lib\\site-packages (from llama-index==0.9.31) (2.0.25)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in .\\llamaindex\\lib\\site-packages (from llama-index==0.9.31) (3.9.1)\n",
            "Requirement already satisfied: numpy in .\\llamaindex\\lib\\site-packages (from llama-index==0.9.31) (1.26.3)\n",
            "Requirement already satisfied: requests>=2.31.0 in .\\llamaindex\\lib\\site-packages (from llama-index==0.9.31) (2.31.0)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in .\\llamaindex\\lib\\site-packages (from llama-index==0.9.31) (0.5.2)\n",
            "Requirement already satisfied: dataclasses-json in .\\llamaindex\\lib\\site-packages (from llama-index==0.9.31) (0.5.14)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in .\\llamaindex\\lib\\site-packages (from llama-index==0.9.31) (2023.12.2)\n",
            "Requirement already satisfied: networkx>=3.0 in .\\llamaindex\\lib\\site-packages (from llama-index==0.9.31) (3.2.1)\n",
            "Requirement already satisfied: pandas in .\\llamaindex\\lib\\site-packages (from llama-index==0.9.31) (2.1.4)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in .\\llamaindex\\lib\\site-packages (from llama-index==0.9.31) (1.2.14)\n",
            "Requirement already satisfied: httpx in .\\llamaindex\\lib\\site-packages (from llama-index==0.9.31) (0.25.2)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in .\\llamaindex\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index==0.9.31) (4.0.3)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in .\\llamaindex\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index==0.9.31) (6.0.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in .\\llamaindex\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index==0.9.31) (1.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in .\\llamaindex\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index==0.9.31) (1.9.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in .\\llamaindex\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index==0.9.31) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in .\\llamaindex\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index==0.9.31) (1.4.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in .\\llamaindex\\lib\\site-packages (from beautifulsoup4<5.0.0,>=4.12.2->llama-index==0.9.31) (2.5)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in .\\llamaindex\\lib\\site-packages (from deprecated>=1.2.9.3->llama-index==0.9.31) (1.16.0)\n",
            "Requirement already satisfied: joblib in .\\llamaindex\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama-index==0.9.31) (1.3.2)\n",
            "Requirement already satisfied: click in .\\llamaindex\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama-index==0.9.31) (8.1.7)\n",
            "Requirement already satisfied: tqdm in .\\llamaindex\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama-index==0.9.31) (4.66.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in .\\llamaindex\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama-index==0.9.31) (2023.12.25)\n",
            "Requirement already satisfied: sniffio in .\\llamaindex\\lib\\site-packages (from openai>=1.1.0->llama-index==0.9.31) (1.3.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in .\\llamaindex\\lib\\site-packages (from openai>=1.1.0->llama-index==0.9.31) (2.5.3)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in .\\llamaindex\\lib\\site-packages (from openai>=1.1.0->llama-index==0.9.31) (1.9.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in .\\llamaindex\\lib\\site-packages (from openai>=1.1.0->llama-index==0.9.31) (4.2.0)\n",
            "Requirement already satisfied: certifi in .\\llamaindex\\lib\\site-packages (from httpx->llama-index==0.9.31) (2023.11.17)\n",
            "Requirement already satisfied: idna in .\\llamaindex\\lib\\site-packages (from httpx->llama-index==0.9.31) (3.6)\n",
            "Requirement already satisfied: httpcore==1.* in .\\llamaindex\\lib\\site-packages (from httpx->llama-index==0.9.31) (1.0.2)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in .\\llamaindex\\lib\\site-packages (from httpcore==1.*->httpx->llama-index==0.9.31) (0.14.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in .\\llamaindex\\lib\\site-packages (from requests>=2.31.0->llama-index==0.9.31) (1.26.18)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in .\\llamaindex\\lib\\site-packages (from requests>=2.31.0->llama-index==0.9.31) (3.3.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in .\\llamaindex\\lib\\site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index==0.9.31) (3.0.3)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in .\\llamaindex\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index==0.9.31) (1.0.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in .\\llamaindex\\lib\\site-packages (from dataclasses-json->llama-index==0.9.31) (3.20.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in .\\llamaindex\\lib\\site-packages (from pandas->llama-index==0.9.31) (2.8.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in .\\llamaindex\\lib\\site-packages (from pandas->llama-index==0.9.31) (2023.4)\n",
            "Requirement already satisfied: pytz>=2020.1 in .\\llamaindex\\lib\\site-packages (from pandas->llama-index==0.9.31) (2023.3.post1)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.2 in .\\llamaindex\\lib\\site-packages (from anyio<5,>=3.5.0->openai>=1.1.0->llama-index==0.9.31) (1.2.0)\n",
            "Requirement already satisfied: packaging>=17.0 in .\\llamaindex\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index==0.9.31) (23.2)\n",
            "Requirement already satisfied: pydantic-core==2.14.6 in .\\llamaindex\\lib\\site-packages (from pydantic<3,>=1.9.0->openai>=1.1.0->llama-index==0.9.31) (2.14.6)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in .\\llamaindex\\lib\\site-packages (from pydantic<3,>=1.9.0->openai>=1.1.0->llama-index==0.9.31) (0.6.0)\n",
            "Requirement already satisfied: six>=1.5 in .\\llamaindex\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->llama-index==0.9.31) (1.16.0)\n",
            "Requirement already satisfied: colorama in .\\llamaindex\\lib\\site-packages (from tqdm->nltk<4.0.0,>=3.8.1->llama-index==0.9.31) (0.4.6)\n",
            "Installing collected packages: llama-index\n",
            "  Attempting uninstall: llama-index\n",
            "    Found existing installation: llama-index 0.9.3\n",
            "    Uninstalling llama-index-0.9.3:\n",
            "      Successfully uninstalled llama-index-0.9.3\n",
            "Successfully installed llama-index-0.9.31\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: You are using pip version 22.0.4; however, version 24.0 is available.\n",
            "You should consider upgrading via the 'C:\\llamaindex\\llamaindex-samples\\llamaindex\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
          ]
        }
      ],
      "source": [
        "!pip install llama-index==0.9.31  wikipedia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "6iiIRp29bnrf"
      },
      "outputs": [],
      "source": [
        "# NOTE: This is ONLY necessary in jupyter notebook.\n",
        "# Details: Jupyter runs an event-loop behind the scenes.\n",
        "#          This results in nested event-loops when we start an event-loop to make async queries.\n",
        "#          This is normally not allowed, we use nest_asyncio to allow it for convenience.\n",
        "import nest_asyncio\n",
        "\n",
        "nest_asyncio.apply()\n",
        "\n",
        "import logging\n",
        "import sys\n",
        "\n",
        "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
        "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "esz4TP8Tbnrg",
        "outputId": "ed66eaa6-e733-4726-a65c-813639a6f602"
      },
      "outputs": [],
      "source": [
        "from llama_index import VectorStoreIndex,SimpleDirectoryReader,ServiceContext,StorageContext,SQLDatabase\n",
        "from llama_index.readers.wikipedia import WikipediaReader\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GRA3yzKrbnrh"
      },
      "source": [
        "### Create Common Objects\n",
        "\n",
        "This includes a `ServiceContext` object containing abstractions such as the LLM and chunk size.\n",
        "This also includes a `StorageContext` object containing our vector store abstractions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "hR5jvTlzbnrh",
        "outputId": "b5450c2d-e597-4f12-9823-c3dd49d46251"
      },
      "outputs": [],
      "source": [
        "from pinecone import Pinecone, PodSpec\n",
        "from tqdm.autonotebook import tqdm\n",
        "\n",
        "pc = Pinecone(api_key=os.environ[\"PINECONE_API_KEY\"])\n",
        "pc_index_name = \"llamaindex-dochelper\"\n",
        "pinecone_index = pc.Index(pc_index_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "NiUrWimUbnri",
        "outputId": "dfbd607e-6601-423c-bdf7-ebba7ef3e6fc"
      },
      "outputs": [
        {
          "ename": "NotFoundException",
          "evalue": "(404)\nReason: Not Found\nHTTP response headers: HTTPHeaderDict({'content-type': 'application/json', 'Content-Length': '55', 'x-pinecone-request-latency-ms': '13', 'x-pinecone-request-id': '3090145275427312615', 'date': 'Sun, 17 Mar 2024 16:35:24 GMT', 'x-envoy-upstream-service-time': '15', 'server': 'envoy', 'Via': '1.1 google', 'Alt-Svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'})\nHTTP response body: {\"code\":5,\"message\":\"Namespace not found\",\"details\":[]}\n",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNotFoundException\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[8], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# OPTIONAL: delete all\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mpinecone_index\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdelete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeleteAll\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\llamaindex\\llamaindex-samples\\llamaindex\\lib\\site-packages\\pinecone\\utils\\error_handling.py:10\u001b[0m, in \u001b[0;36mvalidate_and_convert_errors.<locals>.inner_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner_func\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 10\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m MaxRetryError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     12\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e\u001b[38;5;241m.\u001b[39mreason, ProtocolError):\n",
            "File \u001b[1;32mc:\\llamaindex\\llamaindex-samples\\llamaindex\\lib\\site-packages\\pinecone\\data\\index.py:291\u001b[0m, in \u001b[0;36mIndex.delete\u001b[1;34m(self, ids, delete_all, namespace, filter, **kwargs)\u001b[0m\n\u001b[0;32m    286\u001b[0m _check_type \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_check_type\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    287\u001b[0m args_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse_non_empty_args(\n\u001b[0;32m    288\u001b[0m     [(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mids\u001b[39m\u001b[38;5;124m\"\u001b[39m, ids), (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelete_all\u001b[39m\u001b[38;5;124m\"\u001b[39m, delete_all), (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnamespace\u001b[39m\u001b[38;5;124m\"\u001b[39m, namespace), (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfilter\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mfilter\u001b[39m)]\n\u001b[0;32m    289\u001b[0m )\n\u001b[1;32m--> 291\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_vector_api\u001b[38;5;241m.\u001b[39mdelete(\n\u001b[0;32m    292\u001b[0m     DeleteRequest(\n\u001b[0;32m    293\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39margs_dict,\n\u001b[0;32m    294\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m _OPENAPI_ENDPOINT_PARAMS \u001b[38;5;129;01mand\u001b[39;00m v \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m},\n\u001b[0;32m    295\u001b[0m         _check_type\u001b[38;5;241m=\u001b[39m_check_type,\n\u001b[0;32m    296\u001b[0m     ),\n\u001b[0;32m    297\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m _OPENAPI_ENDPOINT_PARAMS},\n\u001b[0;32m    298\u001b[0m )\n",
            "File \u001b[1;32mc:\\llamaindex\\llamaindex-samples\\llamaindex\\lib\\site-packages\\pinecone\\core\\client\\api_client.py:771\u001b[0m, in \u001b[0;36mEndpoint.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    760\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    761\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" This method is invoked when endpoints are called\u001b[39;00m\n\u001b[0;32m    762\u001b[0m \u001b[38;5;124;03m    Example:\u001b[39;00m\n\u001b[0;32m    763\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    769\u001b[0m \n\u001b[0;32m    770\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallable(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\llamaindex\\llamaindex-samples\\llamaindex\\lib\\site-packages\\pinecone\\core\\client\\api\\vector_operations_api.py:112\u001b[0m, in \u001b[0;36mVectorOperationsApi.__init__.<locals>.__delete\u001b[1;34m(self, delete_request, **kwargs)\u001b[0m\n\u001b[0;32m    109\u001b[0m kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_host_index\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_host_index\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    110\u001b[0m kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdelete_request\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \\\n\u001b[0;32m    111\u001b[0m     delete_request\n\u001b[1;32m--> 112\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_with_http_info(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\llamaindex\\llamaindex-samples\\llamaindex\\lib\\site-packages\\pinecone\\core\\client\\api_client.py:833\u001b[0m, in \u001b[0;36mEndpoint.call_with_http_info\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    829\u001b[0m     header_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_client\u001b[38;5;241m.\u001b[39mselect_header_content_type(\n\u001b[0;32m    830\u001b[0m         content_type_headers_list)\n\u001b[0;32m    831\u001b[0m     params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mheader\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mContent-Type\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m header_list\n\u001b[1;32m--> 833\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapi_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_api\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    834\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msettings\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mendpoint_path\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msettings\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhttp_method\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    835\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpath\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    836\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mquery\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    837\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mheader\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    838\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbody\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    839\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpost_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mform\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    840\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfile\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    841\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msettings\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mresponse_type\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    842\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth_settings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msettings\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mauth\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    843\u001b[0m \u001b[43m    \u001b[49m\u001b[43masync_req\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43masync_req\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    844\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_check_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_check_return_type\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    845\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_return_http_data_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_return_http_data_only\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    846\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_preload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_preload_content\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    847\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_request_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_request_timeout\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    848\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_host\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    849\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollection_formats\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcollection_format\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\llamaindex\\llamaindex-samples\\llamaindex\\lib\\site-packages\\pinecone\\core\\client\\api_client.py:408\u001b[0m, in \u001b[0;36mApiClient.call_api\u001b[1;34m(self, resource_path, method, path_params, query_params, header_params, body, post_params, files, response_type, auth_settings, async_req, _return_http_data_only, collection_formats, _preload_content, _request_timeout, _host, _check_type)\u001b[0m\n\u001b[0;32m    354\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Makes the HTTP request (synchronous) and returns deserialized data.\u001b[39;00m\n\u001b[0;32m    355\u001b[0m \n\u001b[0;32m    356\u001b[0m \u001b[38;5;124;03mTo make an async_req request, set the async_req parameter.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    405\u001b[0m \u001b[38;5;124;03m    then the method will return the response directly.\u001b[39;00m\n\u001b[0;32m    406\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m async_req:\n\u001b[1;32m--> 408\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__call_api\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresource_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    409\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mpath_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheader_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    410\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpost_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    411\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mresponse_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauth_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    412\u001b[0m \u001b[43m                           \u001b[49m\u001b[43m_return_http_data_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollection_formats\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    413\u001b[0m \u001b[43m                           \u001b[49m\u001b[43m_preload_content\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_request_timeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_host\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    414\u001b[0m \u001b[43m                           \u001b[49m\u001b[43m_check_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    416\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool\u001b[38;5;241m.\u001b[39mapply_async(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__call_api, (resource_path,\n\u001b[0;32m    417\u001b[0m                                                method, path_params,\n\u001b[0;32m    418\u001b[0m                                                query_params,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    426\u001b[0m                                                _request_timeout,\n\u001b[0;32m    427\u001b[0m                                                _host, _check_type))\n",
            "File \u001b[1;32mc:\\llamaindex\\llamaindex-samples\\llamaindex\\lib\\site-packages\\pinecone\\core\\client\\api_client.py:202\u001b[0m, in \u001b[0;36mApiClient.__call_api\u001b[1;34m(self, resource_path, method, path_params, query_params, header_params, body, post_params, files, response_type, auth_settings, _return_http_data_only, collection_formats, _preload_content, _request_timeout, _host, _check_type)\u001b[0m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m PineconeApiException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    201\u001b[0m     e\u001b[38;5;241m.\u001b[39mbody \u001b[38;5;241m=\u001b[39m e\u001b[38;5;241m.\u001b[39mbody\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 202\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_response \u001b[38;5;241m=\u001b[39m response_data\n\u001b[0;32m    206\u001b[0m return_data \u001b[38;5;241m=\u001b[39m response_data\n",
            "File \u001b[1;32mc:\\llamaindex\\llamaindex-samples\\llamaindex\\lib\\site-packages\\pinecone\\core\\client\\api_client.py:195\u001b[0m, in \u001b[0;36mApiClient.__call_api\u001b[1;34m(self, resource_path, method, path_params, query_params, header_params, body, post_params, files, response_type, auth_settings, _return_http_data_only, collection_formats, _preload_content, _request_timeout, _host, _check_type)\u001b[0m\n\u001b[0;32m    191\u001b[0m     url \u001b[38;5;241m=\u001b[39m _host \u001b[38;5;241m+\u001b[39m resource_path\n\u001b[0;32m    193\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    194\u001b[0m     \u001b[38;5;66;03m# perform request and return response\u001b[39;00m\n\u001b[1;32m--> 195\u001b[0m     response_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    196\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheader_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpost_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpost_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_preload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_preload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_request_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_request_timeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m PineconeApiException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    201\u001b[0m     e\u001b[38;5;241m.\u001b[39mbody \u001b[38;5;241m=\u001b[39m e\u001b[38;5;241m.\u001b[39mbody\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
            "File \u001b[1;32mc:\\llamaindex\\llamaindex-samples\\llamaindex\\lib\\site-packages\\pinecone\\core\\client\\api_client.py:454\u001b[0m, in \u001b[0;36mApiClient.request\u001b[1;34m(self, method, url, query_params, headers, post_params, body, _preload_content, _request_timeout)\u001b[0m\n\u001b[0;32m    446\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrest_client\u001b[38;5;241m.\u001b[39mOPTIONS(url,\n\u001b[0;32m    447\u001b[0m                                     query_params\u001b[38;5;241m=\u001b[39mquery_params,\n\u001b[0;32m    448\u001b[0m                                     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    451\u001b[0m                                     _request_timeout\u001b[38;5;241m=\u001b[39m_request_timeout,\n\u001b[0;32m    452\u001b[0m                                     body\u001b[38;5;241m=\u001b[39mbody)\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPOST\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 454\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrest_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPOST\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    455\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mquery_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    456\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mpost_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpost_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    458\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43m_preload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_preload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    459\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43m_request_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_request_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    460\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    461\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPUT\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    462\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrest_client\u001b[38;5;241m.\u001b[39mPUT(url,\n\u001b[0;32m    463\u001b[0m                                 query_params\u001b[38;5;241m=\u001b[39mquery_params,\n\u001b[0;32m    464\u001b[0m                                 headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    467\u001b[0m                                 _request_timeout\u001b[38;5;241m=\u001b[39m_request_timeout,\n\u001b[0;32m    468\u001b[0m                                 body\u001b[38;5;241m=\u001b[39mbody)\n",
            "File \u001b[1;32mc:\\llamaindex\\llamaindex-samples\\llamaindex\\lib\\site-packages\\pinecone\\core\\client\\rest.py:301\u001b[0m, in \u001b[0;36mRESTClientObject.POST\u001b[1;34m(self, url, headers, query_params, post_params, body, _preload_content, _request_timeout)\u001b[0m\n\u001b[0;32m    299\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mPOST\u001b[39m(\u001b[38;5;28mself\u001b[39m, url, headers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, query_params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, post_params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    300\u001b[0m          body\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, _preload_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, _request_timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 301\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPOST\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    302\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    303\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mquery_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    304\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mpost_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpost_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    305\u001b[0m \u001b[43m                        \u001b[49m\u001b[43m_preload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_preload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    306\u001b[0m \u001b[43m                        \u001b[49m\u001b[43m_request_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_request_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    307\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\llamaindex\\llamaindex-samples\\llamaindex\\lib\\site-packages\\pinecone\\core\\client\\rest.py:255\u001b[0m, in \u001b[0;36mRESTClientObject.request\u001b[1;34m(self, method, url, query_params, headers, body, post_params, _preload_content, _request_timeout)\u001b[0m\n\u001b[0;32m    252\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ForbiddenException(http_resp\u001b[38;5;241m=\u001b[39mr)\n\u001b[0;32m    254\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m r\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m404\u001b[39m:\n\u001b[1;32m--> 255\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NotFoundException(http_resp\u001b[38;5;241m=\u001b[39mr)\n\u001b[0;32m    257\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;241m500\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m r\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m599\u001b[39m:\n\u001b[0;32m    258\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ServiceException(http_resp\u001b[38;5;241m=\u001b[39mr)\n",
            "\u001b[1;31mNotFoundException\u001b[0m: (404)\nReason: Not Found\nHTTP response headers: HTTPHeaderDict({'content-type': 'application/json', 'Content-Length': '55', 'x-pinecone-request-latency-ms': '13', 'x-pinecone-request-id': '3090145275427312615', 'date': 'Sun, 17 Mar 2024 16:35:24 GMT', 'x-envoy-upstream-service-time': '15', 'server': 'envoy', 'Via': '1.1 google', 'Alt-Svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'})\nHTTP response body: {\"code\":5,\"message\":\"Namespace not found\",\"details\":[]}\n"
          ]
        }
      ],
      "source": [
        "# OPTIONAL: delete all\n",
        "pinecone_index.delete(deleteAll=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "Q2EFe2ZIbnri"
      },
      "outputs": [],
      "source": [
        "from llama_index import ServiceContext\n",
        "from llama_index.storage import StorageContext\n",
        "from llama_index.vector_stores import PineconeVectorStore\n",
        "from llama_index.node_parser import TokenTextSplitter\n",
        "from llama_index.llms import OpenAI\n",
        "\n",
        "# define node parser and LLM\n",
        "chunk_size = 1024\n",
        "llm = OpenAI(temperature=0, model=\"gpt-4\", streaming=True)\n",
        "service_context = ServiceContext.from_defaults(chunk_size=chunk_size, llm=llm)\n",
        "node_parser = TokenTextSplitter(chunk_size=chunk_size)\n",
        "\n",
        "# define pinecone vector index\n",
        "vector_store = PineconeVectorStore(\n",
        "    pinecone_index=pinecone_index, namespace=\"wiki_cities\"\n",
        ")\n",
        "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
        "vector_index = VectorStoreIndex([], storage_context=storage_context)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ltjfSOcbnri"
      },
      "source": [
        "### Create Database Schema + Test Data\n",
        "\n",
        "Here we introduce a toy scenario where there are 100 tables (too big to fit into the prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "Nonnz4m0bnri"
      },
      "outputs": [],
      "source": [
        "from sqlalchemy import (\n",
        "    create_engine,\n",
        "    MetaData,\n",
        "    Table,\n",
        "    Column,\n",
        "    String,\n",
        "    Integer,\n",
        "    select,\n",
        "    column,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "xjBdo0Uebnrj"
      },
      "outputs": [],
      "source": [
        "engine = create_engine(\"sqlite:///:memory:\", future=True)\n",
        "metadata_obj = MetaData()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "fsPY2JOGbnrj"
      },
      "outputs": [],
      "source": [
        "# create city SQL table\n",
        "table_name = \"city_stats\"\n",
        "city_stats_table = Table(\n",
        "    table_name,\n",
        "    metadata_obj,\n",
        "    Column(\"city_name\", String(16), primary_key=True),\n",
        "    Column(\"population\", Integer),\n",
        "    Column(\"country\", String(16), nullable=False),\n",
        ")\n",
        "\n",
        "metadata_obj.create_all(engine)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "ouaICqKGbnrj",
        "outputId": "fa9d3ea0-f2ee-4447-beb6-ac79c4dc09a0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['city_stats'])"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# print tables\n",
        "metadata_obj.tables.keys()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RnJ6rVnJbnrj"
      },
      "source": [
        "We introduce some test data into the `city_stats` table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "JWJELwV5bnrj"
      },
      "outputs": [],
      "source": [
        "from sqlalchemy import insert\n",
        "\n",
        "rows = [\n",
        "    {\"city_name\": \"Toronto\", \"population\": 2930000, \"country\": \"Canada\"},\n",
        "    {\"city_name\": \"Tokyo\", \"population\": 13960000, \"country\": \"Japan\"},\n",
        "    {\"city_name\": \"Berlin\", \"population\": 3645000, \"country\": \"Germany\"},\n",
        "]\n",
        "for row in rows:\n",
        "    stmt = insert(city_stats_table).values(**row)\n",
        "    with engine.begin() as connection:\n",
        "        cursor = connection.execute(stmt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "aNg0Gu8ybnrj",
        "outputId": "65cb4647-f9ba-4b4d-ef84-d8e6ba2774ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('Toronto', 2930000, 'Canada'), ('Tokyo', 13960000, 'Japan'), ('Berlin', 3645000, 'Germany')]\n"
          ]
        }
      ],
      "source": [
        "with engine.connect() as connection:\n",
        "    cursor = connection.exec_driver_sql(\"SELECT * FROM city_stats\")\n",
        "    print(cursor.fetchall())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szVpj3-Xbnrj"
      },
      "source": [
        "### Load Data\n",
        "\n",
        "We first show how to convert a Document into a set of Nodes, and insert into a DocumentStore."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "r1OaX2Vabnrj",
        "outputId": "2e710f01-a216-4819-b7e7-e84cf8e6f1b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: wikipedia in .\\llamaindex\\lib\\site-packages (1.4.0)\n",
            "Requirement already satisfied: beautifulsoup4 in .\\llamaindex\\lib\\site-packages (from wikipedia) (4.12.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in .\\llamaindex\\lib\\site-packages (from wikipedia) (2.31.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in .\\llamaindex\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in .\\llamaindex\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in .\\llamaindex\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (1.26.18)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in .\\llamaindex\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2023.11.17)\n",
            "Requirement already satisfied: soupsieve>1.2 in .\\llamaindex\\lib\\site-packages (from beautifulsoup4->wikipedia) (2.5)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: You are using pip version 22.0.4; however, version 24.0 is available.\n",
            "You should consider upgrading via the 'C:\\llamaindex\\llamaindex-samples\\llamaindex\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
          ]
        }
      ],
      "source": [
        "# install wikipedia python package\n",
        "!pip install wikipedia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "7v2wMYJXbnrk"
      },
      "outputs": [],
      "source": [
        "cities = [\"Toronto\", \"Berlin\", \"Tokyo\"]\n",
        "wiki_docs = WikipediaReader().load_data(pages=cities)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XdaqYWrwbnrk"
      },
      "source": [
        "### Build SQL Index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "d6x-zfqibnrk"
      },
      "outputs": [],
      "source": [
        "sql_database = SQLDatabase(engine, include_tables=[\"city_stats\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "cAxLHk9Zbnrk"
      },
      "outputs": [],
      "source": [
        "from llama_index.indices.struct_store.sql_query import NLSQLTableQueryEngine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "fh1G4PT2bnrk"
      },
      "outputs": [],
      "source": [
        "sql_query_engine = NLSQLTableQueryEngine(\n",
        "    sql_database=sql_database,\n",
        "    tables=[\"city_stats\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PYOtLFZ0bnrk"
      },
      "source": [
        "### Build Vector Index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "yjV8uyd3bnrk",
        "outputId": "da65d019-3e67-45d2-a317-58df48b69fee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Upserted vectors: 100%|██████████| 18/18 [00:02<00:00,  8.19it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Upserted vectors: 100%|██████████| 17/17 [00:02<00:00,  6.31it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Upserted vectors: 100%|██████████| 11/11 [00:02<00:00,  4.53it/s]\n"
          ]
        }
      ],
      "source": [
        "# Insert documents into vector index\n",
        "# Each document has metadata of the city attached\n",
        "for city, wiki_doc in zip(cities, wiki_docs):\n",
        "    nodes = node_parser.get_nodes_from_documents([wiki_doc])\n",
        "    # add metadata to each node\n",
        "    for node in nodes:\n",
        "        node.metadata = {\"title\": city}\n",
        "    vector_index.insert_nodes(nodes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fv0t7p1ebnrk"
      },
      "source": [
        "### Define Query Engines, Set as Tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "CfbyXclAbnrk"
      },
      "outputs": [],
      "source": [
        "from llama_index.query_engine import (\n",
        "    SQLAutoVectorQueryEngine,\n",
        "    RetrieverQueryEngine,\n",
        ")\n",
        "from llama_index.tools.query_engine import QueryEngineTool\n",
        "from llama_index.indices.vector_store import VectorIndexAutoRetriever"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "WNg2bIWAbnrk"
      },
      "outputs": [],
      "source": [
        "from llama_index.indices.vector_store.retrievers import (\n",
        "    VectorIndexAutoRetriever,\n",
        ")\n",
        "from llama_index.vector_stores.types import MetadataInfo, VectorStoreInfo\n",
        "from llama_index.query_engine.retriever_query_engine import (\n",
        "    RetrieverQueryEngine,\n",
        ")\n",
        "\n",
        "\n",
        "vector_store_info = VectorStoreInfo(\n",
        "    content_info=\"articles about different cities\",\n",
        "    metadata_info=[\n",
        "        MetadataInfo(\n",
        "            name=\"title\", type=\"str\", description=\"The name of the city\"\n",
        "        ),\n",
        "    ],\n",
        ")\n",
        "vector_auto_retriever = VectorIndexAutoRetriever(\n",
        "    vector_index, vector_store_info=vector_store_info\n",
        ")\n",
        "\n",
        "retriever_query_engine = RetrieverQueryEngine.from_args(\n",
        "    vector_auto_retriever, service_context=service_context\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "Dlxme0UXbnrk"
      },
      "outputs": [],
      "source": [
        "sql_tool = QueryEngineTool.from_defaults(\n",
        "    query_engine=sql_query_engine,\n",
        "    description=(\n",
        "        \"Useful for translating a natural language query into a SQL query over\"\n",
        "        \" a table containing: city_stats, containing the population/country of\"\n",
        "        \" each city\"\n",
        "    ),\n",
        ")\n",
        "vector_tool = QueryEngineTool.from_defaults(\n",
        "    query_engine=retriever_query_engine,\n",
        "    description=(\n",
        "        f\"Useful for answering semantic questions about different cities\"\n",
        "    ),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ez41vTuRbnrl"
      },
      "source": [
        "### Define SQLAutoVectorQueryEngine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "ZWIV1exybnrl"
      },
      "outputs": [],
      "source": [
        "query_engine = SQLAutoVectorQueryEngine(\n",
        "    sql_tool, vector_tool, service_context=service_context\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "62Eg-0iRbnrl",
        "outputId": "cce16d33-3bc7-4f05-bfe0-b5e06b8c17aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "\u001b[1;3;34mQuerying SQL database: The first choice is more relevant as it mentions 'city_stats' and 'population' which could be used to determine the city with the highest population. The second choice does not provide any specific information that could be used to answer the question.\n",
            "\u001b[0mINFO:llama_index.query_engine.sql_join_query_engine:> Querying SQL database: The first choice is more relevant as it mentions 'city_stats' and 'population' which could be used to determine the city with the highest population. The second choice does not provide any specific information that could be used to answer the question.\n",
            "> Querying SQL database: The first choice is more relevant as it mentions 'city_stats' and 'population' which could be used to determine the city with the highest population. The second choice does not provide any specific information that could be used to answer the question.\n",
            "INFO:llama_index.indices.struct_store.sql_retriever:> Table desc str: Table 'city_stats' has columns: city_name (VARCHAR(16)), population (INTEGER), country (VARCHAR(16)), and foreign keys: .\n",
            "> Table desc str: Table 'city_stats' has columns: city_name (VARCHAR(16)), population (INTEGER), country (VARCHAR(16)), and foreign keys: .\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "\u001b[1;3;33mSQL query: SELECT city_name, population, country\n",
            "FROM city_stats\n",
            "ORDER BY population DESC\n",
            "LIMIT 1;\n",
            "\u001b[0m\u001b[1;3;33mSQL response: Tokyo, Japan has the highest population of any city. Its arts and culture scene is incredibly diverse and vibrant, with a mix of traditional Japanese arts like tea ceremonies and kabuki theater, as well as modern influences such as anime and manga. The city is home to numerous museums, galleries, and performance venues, showcasing a wide range of artistic expressions. Additionally, Tokyo's neighborhoods each have their own unique character and offer a variety of cultural experiences for residents and visitors alike.\n",
            "\u001b[0mINFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "\u001b[1;3;34mTransformed query given SQL response: Can you provide more specific examples of the arts and culture venues in Tokyo, Japan?\n",
            "\u001b[0mINFO:llama_index.query_engine.sql_join_query_engine:> Transformed query given SQL response: Can you provide more specific examples of the arts and culture venues in Tokyo, Japan?\n",
            "> Transformed query given SQL response: Can you provide more specific examples of the arts and culture venues in Tokyo, Japan?\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "WARNING:llama_index.indices.vector_store.retrievers.auto_retriever.auto_retriever:Failed to parse query spec, using defaults as fallback.\n",
            "Failed to parse query spec, using defaults as fallback.\n",
            "INFO:llama_index.indices.vector_store.retrievers.auto_retriever.auto_retriever:Using query str: Can you provide more specific examples of the arts and culture venues in Tokyo, Japan?\n",
            "Using query str: Can you provide more specific examples of the arts and culture venues in Tokyo, Japan?\n",
            "INFO:llama_index.indices.vector_store.retrievers.auto_retriever.auto_retriever:Using filters: []\n",
            "Using filters: []\n",
            "INFO:llama_index.indices.vector_store.retrievers.auto_retriever.auto_retriever:Using top_k: 2\n",
            "Using top_k: 2\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "\u001b[1;3;38;5;200mquery engine response: Tokyo is home to a variety of arts and culture venues. The Tokyo National Museum, which is the country's largest museum specializing in traditional Japanese art, is located in Ueno Park. Other museums include the National Museum of Western Art, the Artizon Museum in Chūō, the National Museum of Emerging Science and Innovation in Odaiba, the Edo-Tokyo Museum in Sumida, the Nezu Museum in Aoyama, and the National Diet Library, National Archives, and the National Museum of Modern Art, which are near the Imperial Palace.\n",
            "\n",
            "For performing arts, there are national and private theaters for traditional forms of Japanese drama. The National Noh Theatre is dedicated to Noh, and the Kabuki-za is for Kabuki. The New National Theater Tokyo in Shibuya is the national center for the performing arts, including opera, ballet, contemporary dance, and drama. Tokyo also hosts modern Japanese and international pop, and rock music at venues ranging in size from intimate clubs to internationally known areas such as the Nippon Budokan.\n",
            "\u001b[0mINFO:llama_index.query_engine.sql_join_query_engine:> query engine response: Tokyo is home to a variety of arts and culture venues. The Tokyo National Museum, which is the country's largest museum specializing in traditional Japanese art, is located in Ueno Park. Other museums include the National Museum of Western Art, the Artizon Museum in Chūō, the National Museum of Emerging Science and Innovation in Odaiba, the Edo-Tokyo Museum in Sumida, the Nezu Museum in Aoyama, and the National Diet Library, National Archives, and the National Museum of Modern Art, which are near the Imperial Palace.\n",
            "\n",
            "For performing arts, there are national and private theaters for traditional forms of Japanese drama. The National Noh Theatre is dedicated to Noh, and the Kabuki-za is for Kabuki. The New National Theater Tokyo in Shibuya is the national center for the performing arts, including opera, ballet, contemporary dance, and drama. Tokyo also hosts modern Japanese and international pop, and rock music at venues ranging in size from intimate clubs to internationally known areas such as the Nippon Budokan.\n",
            "> query engine response: Tokyo is home to a variety of arts and culture venues. The Tokyo National Museum, which is the country's largest museum specializing in traditional Japanese art, is located in Ueno Park. Other museums include the National Museum of Western Art, the Artizon Museum in Chūō, the National Museum of Emerging Science and Innovation in Odaiba, the Edo-Tokyo Museum in Sumida, the Nezu Museum in Aoyama, and the National Diet Library, National Archives, and the National Museum of Modern Art, which are near the Imperial Palace.\n",
            "\n",
            "For performing arts, there are national and private theaters for traditional forms of Japanese drama. The National Noh Theatre is dedicated to Noh, and the Kabuki-za is for Kabuki. The New National Theater Tokyo in Shibuya is the national center for the performing arts, including opera, ballet, contemporary dance, and drama. Tokyo also hosts modern Japanese and international pop, and rock music at venues ranging in size from intimate clubs to internationally known areas such as the Nippon Budokan.\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "\u001b[1;3;32mFinal response: Tokyo, Japan, the city with the highest population, boasts a diverse and vibrant arts and culture scene. It is a blend of traditional Japanese arts like tea ceremonies and kabuki theater, and modern influences such as anime and manga. The city is home to numerous museums, galleries, and performance venues, showcasing a wide range of artistic expressions. Tokyo's neighborhoods each have their own unique character and offer a variety of cultural experiences.\n",
            "\n",
            "Specifically, Tokyo houses the Tokyo National Museum, the country's largest museum specializing in traditional Japanese art. Other museums include the National Museum of Western Art, the Artizon Museum, the National Museum of Emerging Science and Innovation, the Edo-Tokyo Museum, the Nezu Museum, and the National Diet Library, National Archives, and the National Museum of Modern Art. \n",
            "\n",
            "For performing arts, there are national and private theaters for traditional forms of Japanese drama. The National Noh Theatre is dedicated to Noh, and the Kabuki-za is for Kabuki. The New National Theater Tokyo in Shibuya is the national center for the performing arts, including opera, ballet, contemporary dance, and drama. Tokyo also hosts modern Japanese and international pop, and rock music at venues ranging in size from intimate clubs to internationally known areas such as the Nippon Budokan.\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "response = query_engine.query(\n",
        "    \"Tell me about the arts and culture of the city with the highest\"\n",
        "    \" population\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "KYuTgNcobnrl",
        "outputId": "748d55e1-bc0d-4a8b-c53a-d54275f1ff19"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tokyo, Japan, the city with the highest population, boasts a diverse and vibrant arts and culture scene. It is a blend of traditional Japanese arts like tea ceremonies and kabuki theater, and modern influences such as anime and manga. The city is home to numerous museums, galleries, and performance venues, showcasing a wide range of artistic expressions. Tokyo's neighborhoods each have their own unique character and offer a variety of cultural experiences.\n",
            "\n",
            "Specifically, Tokyo houses the Tokyo National Museum, the country's largest museum specializing in traditional Japanese art. Other museums include the National Museum of Western Art, the Artizon Museum, the National Museum of Emerging Science and Innovation, the Edo-Tokyo Museum, the Nezu Museum, and the National Diet Library, National Archives, and the National Museum of Modern Art. \n",
            "\n",
            "For performing arts, there are national and private theaters for traditional forms of Japanese drama. The National Noh Theatre is dedicated to Noh, and the Kabuki-za is for Kabuki. The New National Theater Tokyo in Shibuya is the national center for the performing arts, including opera, ballet, contemporary dance, and drama. Tokyo also hosts modern Japanese and international pop, and rock music at venues ranging in size from intimate clubs to internationally known areas such as the Nippon Budokan.\n"
          ]
        }
      ],
      "source": [
        "print(str(response))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "7GCoX8Zjbnrl",
        "outputId": "f3170771-433a-4d5b-8ea2-ad7f4d6b5a77"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "\u001b[1;3;34mQuerying other query engine: The second choice seems more relevant to the question as it mentions answering semantic questions about different cities, which could include historical information. The first choice is more about translating queries into SQL, which doesn't seem directly related to the question about Berlin's history.\n",
            "\u001b[0mINFO:llama_index.query_engine.sql_join_query_engine:> Querying other query engine: The second choice seems more relevant to the question as it mentions answering semantic questions about different cities, which could include historical information. The first choice is more about translating queries into SQL, which doesn't seem directly related to the question about Berlin's history.\n",
            "> Querying other query engine: The second choice seems more relevant to the question as it mentions answering semantic questions about different cities, which could include historical information. The first choice is more about translating queries into SQL, which doesn't seem directly related to the question about Berlin's history.\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:llama_index.indices.vector_store.retrievers.auto_retriever.auto_retriever:Using query str: history of Berlin\n",
            "Using query str: history of Berlin\n",
            "INFO:llama_index.indices.vector_store.retrievers.auto_retriever.auto_retriever:Using filters: []\n",
            "Using filters: []\n",
            "INFO:llama_index.indices.vector_store.retrievers.auto_retriever.auto_retriever:Using top_k: 2\n",
            "Using top_k: 2\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "\u001b[1;3;38;5;200mQuery Engine response: Berlin's history is rich and varied, dating back to around 9,000 BC with the Maglemosian culture. By 2,000 BC, dense human settlements had formed along the Spree and Havel rivers, giving rise to the Lusatian culture. Germanic tribes settled in the area around 500 BC, followed by the Burgundians after the Semnones left around 200 AD. In the 7th century, Slavic tribes reached the region.\n",
            "\n",
            "In the 12th century, the region came under German rule as part of the Margraviate of Brandenburg, founded by Albert the Bear. The first written records of towns in the area of present-day Berlin date from the late 12th century. The two towns of Spandau and Köpenick formed close economic and social ties, and in 1307, they formed an alliance with a common external policy. The Hohenzollern family ruled in Berlin until 1918, first as electors of Brandenburg, then as kings of Prussia, and eventually as German emperors.\n",
            "\n",
            "The Thirty Years' War between 1618 and 1648 devastated Berlin, with one third of its houses damaged or destroyed, and the city losing half of its population. However, Frederick William, known as the \"Great Elector\", initiated a policy of promoting immigration and religious tolerance. By 1700, approximately 30 percent of Berlin's residents were French, due to the Huguenot immigration.\n",
            "\n",
            "In the early 20th century, Berlin had become a fertile ground for the German Expressionist movement. After the end of the First World War in 1918, a republic was proclaimed by Philipp Scheidemann at the Reichstag building. During the Weimar era, Berlin underwent political unrest due to economic uncertainties but also became a renowned center of the Roaring Twenties. In 1933, Adolf Hitler and the Nazi Party came to power, leading to a significant decrease in Berlin's Jewish community due to emigration and deportation.\n",
            "\n",
            "After World War II, Berlin was divided into four sectors by the victorious powers, forming West Berlin and East Berlin. The city was further divided by the Berlin Wall in 1961, with travel between the two sides heavily restricted. The wall fell in 1989, marking the end of the division. Today, Berlin stands as a vibrant city known for its historical significance and cultural contributions.\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "response = query_engine.query(\"Tell me about the history of Berlin\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "WGHJzdD5bnrl",
        "outputId": "a229627c-0a3b-417a-eabb-d6f5cb723fe6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Berlin's history is rich and varied, dating back to around 9,000 BC with the Maglemosian culture. By 2,000 BC, dense human settlements had formed along the Spree and Havel rivers, giving rise to the Lusatian culture. Germanic tribes settled in the area around 500 BC, followed by the Burgundians after the Semnones left around 200 AD. In the 7th century, Slavic tribes reached the region.\n",
            "\n",
            "In the 12th century, the region came under German rule as part of the Margraviate of Brandenburg, founded by Albert the Bear. The first written records of towns in the area of present-day Berlin date from the late 12th century. The two towns of Spandau and Köpenick formed close economic and social ties, and in 1307, they formed an alliance with a common external policy. The Hohenzollern family ruled in Berlin until 1918, first as electors of Brandenburg, then as kings of Prussia, and eventually as German emperors.\n",
            "\n",
            "The Thirty Years' War between 1618 and 1648 devastated Berlin, with one third of its houses damaged or destroyed, and the city losing half of its population. However, Frederick William, known as the \"Great Elector\", initiated a policy of promoting immigration and religious tolerance. By 1700, approximately 30 percent of Berlin's residents were French, due to the Huguenot immigration.\n",
            "\n",
            "In the early 20th century, Berlin had become a fertile ground for the German Expressionist movement. After the end of the First World War in 1918, a republic was proclaimed by Philipp Scheidemann at the Reichstag building. During the Weimar era, Berlin underwent political unrest due to economic uncertainties but also became a renowned center of the Roaring Twenties. In 1933, Adolf Hitler and the Nazi Party came to power, leading to a significant decrease in Berlin's Jewish community due to emigration and deportation.\n",
            "\n",
            "After World War II, Berlin was divided into four sectors by the victorious powers, forming West Berlin and East Berlin. The city was further divided by the Berlin Wall in 1961, with travel between the two sides heavily restricted. The wall fell in 1989, marking the end of the division. Today, Berlin stands as a vibrant city known for its historical significance and cultural contributions.\n"
          ]
        }
      ],
      "source": [
        "print(str(response))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "TqLVHawSbnrp",
        "outputId": "d2ae5670-c2f0-4b2f-aa3f-db184ced3b12"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "\u001b[1;3;34mQuerying SQL database: The first choice is most relevant as it mentions translating a natural language query into a SQL query over a table containing city_stats, which includes the country of each city. This aligns with the requirement of the question to provide the country corresponding to each city.\n",
            "\u001b[0mINFO:llama_index.query_engine.sql_join_query_engine:> Querying SQL database: The first choice is most relevant as it mentions translating a natural language query into a SQL query over a table containing city_stats, which includes the country of each city. This aligns with the requirement of the question to provide the country corresponding to each city.\n",
            "> Querying SQL database: The first choice is most relevant as it mentions translating a natural language query into a SQL query over a table containing city_stats, which includes the country of each city. This aligns with the requirement of the question to provide the country corresponding to each city.\n",
            "INFO:llama_index.indices.struct_store.sql_retriever:> Table desc str: Table 'city_stats' has columns: city_name (VARCHAR(16)), population (INTEGER), country (VARCHAR(16)), and foreign keys: .\n",
            "> Table desc str: Table 'city_stats' has columns: city_name (VARCHAR(16)), population (INTEGER), country (VARCHAR(16)), and foreign keys: .\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "\u001b[1;3;33mSQL query: SELECT city_name, country\n",
            "FROM city_stats\n",
            "ORDER BY city_name;\n",
            "\u001b[0m\u001b[1;3;33mSQL response: The corresponding countries for each city are Germany for Berlin, Japan for Tokyo, and Canada for Toronto.\n",
            "\u001b[0mINFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "\u001b[1;3;34mTransformed query given SQL response: None\n",
            "\u001b[0mINFO:llama_index.query_engine.sql_join_query_engine:> Transformed query given SQL response: None\n",
            "> Transformed query given SQL response: None\n"
          ]
        }
      ],
      "source": [
        "response = query_engine.query(\n",
        "    \"Can you give me the country corresponding to each city?\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "1yqdHK3Wbnrp",
        "outputId": "f04966c6-8f84-45ae-ee5f-268252a751bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The corresponding countries for each city are Germany for Berlin, Japan for Tokyo, and Canada for Toronto.\n"
          ]
        }
      ],
      "source": [
        "print(str(response))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "llama-index",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
